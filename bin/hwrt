#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""hwrt, the handwriting recognition toolkit, is a set of executable scripts
   and Python modules that are useful for handwriting recognition.

   For train.py, test.py you will need an internal toolkit for training of
   neural networks. The backup.py script is only useful if you have a
   website like write-math.com to collect recordings.
"""


import argparse

import logging
import sys
logging.basicConfig(format='%(asctime)s %(levelname)s %(message)s',
                    level=logging.DEBUG,
                    stream=sys.stdout)

# hwrt modules
# Every HWR tool that should be available through
#   hwrt TOOL
# has to be added to ``get_parser()`` and to ``main``.
import hwrt
from hwrt import create_pfiles
from hwrt import create_model
from hwrt import selfcheck
from hwrt import view
from hwrt import download
from hwrt import analyze_data
from hwrt import serve


def get_parser():
    """Return the parser object for this script."""
    parser = argparse.ArgumentParser(description=__doc__,
                                     prog='hwrt')
    parser.add_argument('--version',
                        action='version',
                        version=('hwrt %s' % str(hwrt.__version__)))
    subparsers = parser.add_subparsers(dest='cmd')
    subparsers.add_parser('check',
                          add_help=False,
                          help="Self-check of the HWRT toolkit.")
    subparsers.add_parser('view',
                          add_help=False,
                          parents=[view.get_parser()],
                          help=("Display raw preprocessed recordings."))
    subparsers.add_parser('download',
                          add_help=False,
                          parents=[download.get_parser()],
                          help=("Download the raw data to start analyzation "
                                "/ traning."))
    subparsers.add_parser('analyze_data',
                          add_help=False,
                          parents=[analyze_data.get_parser()],
                          help=("Analyze data according to many metrics."))
    subparsers.add_parser('create_pfiles',
                          add_help=False,
                          description="Create pfiles",
                          parents=[create_pfiles.get_parser()],
                          help=("A tool to create compressed feature files "
                                "from preprocessed files."))
    subparsers.add_parser('create_model',
                          add_help=False,
                          parents=[create_model.get_parser()],
                          help=("Create a model file."))
    subparsers.add_parser('serve',
                          add_help=False,
                          parents=[serve.get_parser()],
                          help=("Start a web-server which can classify "
                                "recordings.")
                          )
    return parser


def main(args):
    if args.cmd == 'check':
        selfcheck.main()
    elif args.cmd == 'view':
        view.main(args.list, args.model, args.server, args.id, args.show_raw,
                  args.mysql)
    elif args.cmd == 'download':
        download.main()
    elif args.cmd == 'analyze_data':
        analyze_data.main(args.handwriting_datasets, args.analyze_features)
    elif args.cmd == 'create_pfiles':
        create_pfiles.main(args.folder, args.create_learning_curve)
    elif args.cmd == 'create_model':
        create_model.main(args.model, args.override)
    elif args.cmd == 'serve':
        serve.main(args.port, args.n)
    else:
        logging.error("Command '%s' is not implemented yet.", args.cmd)

if __name__ == '__main__':
    args = get_parser().parse_args()
    main(args)
